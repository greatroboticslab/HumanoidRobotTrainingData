Webinar: Measuring Performance in Ag Extension: Common Metrics Framework
https://www.youtube.com/watch?v=-niCVAfkHXw
Nonprofits & Activism
 Hello everyone. On behalf of AgriLynx, Feed the Future, and the USAID Bureau for Food Security, I would like to welcome you to our webinar today on Measuring Performance in Agricultural Extension, a Common Metrics Framework. My name is Julie McCarty, and I'm with the USAID Bureau for Food Security, and I'll be your webinar facilitator today. So you'll hear my voice periodically, especially during our question and answer session. Before we dive into the content, I'd like to go over a few housekeeping items to orient you to the webinar. First, and many of you have done this already, please do use the chat box to introduce yourselves and let us know where you're coming from. The chat box is your main way to communicate today, and we encourage you to use it to post your questions at any point, to share resources, and to discuss this topic with your colleagues. We'll be collecting your questions throughout the webinar, and we'll try to answer some of them along the way in the chat box, and we'll hold the rest until after the presentation. You'll see that the slides are currently available for download in the little box in the bottom left of your screen, and there are also some recommended links, so we encourage you to explore those throughout the webinar. And lastly, we are recording this webinar, and we'll email you the recording, the transcript, and some additional resources once they are ready, and they'll also be posted on the AgriLynx website, so you'll be able to forward this on to your colleagues as desired. All right, let's talk about extension. As many of you know, Agricultural Extension and Advisory Services provide essential support to smallholder farmers by providing them with the knowledge and tools about modern practices and technologies, by facilitating co-learning within communities, and by increasing access to finance and market solutions, among other roles. And as such, Ag Extension is very fundamental to feed the future's work with smallholder farming communities. I expect that many of you have joined today because you see value in having an established set of metrics to compare and contrast the performance of extension systems across different countries and contexts. And the Feed the Future Developing Local Extension Capacity, or DELEC project, is leading an initiative to develop a common framework for extension metrics. And we're excited to have three speakers on hand today to discuss this. So I'll go ahead and introduce our speakers, and then I will hand it over to them. All right, so first up will be Kristen Davis, who is a Senior Research Fellow with the International Food Policy Research Institute, and has been there since 2004. Her research involves research and capacity strengthening on agricultural extension, education, and agricultural innovation systems. And she is currently the project director for the USAID-funded project, Developing Local Extension Capacity, or DELEC. Next up will be David Spielman, who is a Senior Research Fellow, also at IFPRI, and has also been there since 2004. And he leads the Institute's Program on Science, Technology, and Innovation Policy. And then we will also have Judy Payne, who was USAID's Digital Solutions Advisor for Agriculture until just recently, in 2017, and is now an independent consultant with the same focus. And she's currently helping USAID missions and their projects use digital tools to increase the reach and impact. And so I'll go ahead and pass the mic over to Kristen. Thank you very much, Julie, and good day to all of you. Thank you so much for joining this webinar, and I hope we'll have plenty of time for discussion. So I'm going to try to advance the slides here, and start with an introduction to the topic. And I'd like to give you some background on the initiative that Julie mentioned to develop a common framework for extension metrics. To date, no common framework exists, but we do see value in having a common set of metrics to consistently assess extension performance across countries and also across contexts. I think a set of common metrics would help us to share and adapt learning, to guide policymakers and funders and implementers as well with regard to how to invest in an extension. Also just to innovate and to maximize impact. As I said, there is no common framework, but where the initiative started then was with the Best Fit Framework, which is a conceptual framework developed by the International Food Policy Research Institute. The Best Fit Framework suggests an impact chain approach, but first let me explain a little bit more what this framework is all about. The premise of the Best Fit Framework is there is no one-size-fits-all solution to extension and advisory services, and we need local, context-specific, and customized, or best-fit solutions to designing impactful extension. How does this work? We start with the extension system characteristics, and these have to be adapted or fit to the frame conditions. And you can see the frame conditions here surrounding the box in green. It's the political system, whether it's centralized or decentralized, it's the farming systems and production, input and output markets, it's the business environment and civil society, etc. Just a little pause here, Julie, to make sure everything's working fine. No problems? Good. Going to continue. Great. So let's dig a little deeper here into the characteristics of the extension system and how they lead to performance. In the previous slide here, I showed you how the characteristics lead to performance, which lead to outcomes or changes in behavior, and then ultimate impacts. Digging a little deeper into the extension system characteristics and how they affect the performance, we first of all have governance and management structures, things like human resource management, the incentives and career paths, if any, monitoring and evaluation. We then have both organizational and individual capacities of the extension services. And for individual agents, this includes technical skills, but also your functional or soft skills as well, which they need for their job. And then we also have the methods which characterize extension services, the ways in which extension interacts with farmers, depending on their audience, whether they're trying to reach women or youth, teach something complicated, where you might use farmer field schools, or something where you use radio or demonstrations. All of these characteristics, which, as I said, are fit to the frame conditions, then affect the performance of the systems. And by performance, we're talking about things like quality, relevance, timeliness, demand drive, effectiveness, and efficiency. But where the best fit framework falls short is in establishing a common set of indicators against which to measure performance. So that's what we want to talk about today. And that brings us to the initiative for a common framework for metrics. The initiative, as Julie mentioned, is led by the Feed the Future Developing Local Extension Capacity, together with Bill and Melinda Gates Foundation, the World Bank, and of course USAID. And this initiative came out of some joint discussions on how to transform extension globally, including things like pluralism and the use of information and communication technologies, or ICT. There is a task force within the initiative that is working on this framework for common metrics, which will be discussed actually in a face-to-face meeting in Uganda in February 2019. And we're hoping to bring together some potential adopters of the framework, especially governments, to see how they're going to use the framework and what we can do with it. The task force upfront decided that the metrics we're going to look at are going to be aspirational, which means data that we want to have, not necessarily that we know we can get. But also we'll focus on the public sector, but within a pluralistic context, and perhaps with modules for further users like the private sector and civil society. What have we done to date as the Extension Metrics Task Force? We've come up with a set of definitions of terms. We've come up with a framework for the common metrics that includes outcome pillars or goals of extension, the target audience, and the domains across which we would like to measure extension. And then we've taken and mapped potential metrics or data or indicators across the framework, across the pillars, the target audience, and the domains to identify gaps and overlaps. And I'm going to cover each one of these one by one very quickly. We have defined extension and advisory services broadly and in a pluralistic sense to be all of the services and information needed and demanded by producers that is aimed at developing their technical, organizational, and management capacity and empowering them to make better decisions with regard to their agricultural enterprise. We then looked at the ultimate goals or the outcome pillars that most extension services have. They have one or more of these goals. One of these is with regard to productivity and income. This means that producers are reaching their maximum productivity and income potential from the agricultural activities. A second goal many extension programs have is sustainable resilience, where producers mitigate, adapt to, and recover from shocks and stresses in a way that reduces chronic vulnerability, while at the same time ensuring environmental sustainability. And then a third pillar is surrounding empowerment and equity. And here we're saying that all producers, including those that are marginalized or vulnerable, the poor, sometimes women, youth, pastoralists, all of these people have access to fair agricultural opportunities, to agency, and to human capital in order to make better farming decisions. So those are our pillars. Looking at the target audience, I said we're going to focus on the public sector. This is your governments, your public research organizations, your policy makers. But we also think this framework might be applicable to the private sector, agribusinesses, private service providers, and then broadly defined to civil society as well. These include your donors, nonprofits and NGOs, cooperatives, and farmer organizations. And then the last area we're looking at is the domains within the extension system. We start with the systems, which are your overall extension structures, the institutions, networks, and incentive. Things like linkages between organizations or policies that guide extension, or even your share of the public budget. The second area is that of inputs. These are the resources that are used to implement extension activities, like your extension agent workforce, the government budget per household, and things like that. The third domain is that of delivery, the processes and actions taken to achieve outputs and deliver or achieve outcomes. And this is your organization and management, quality assurance, training, or even use of ICT, information and communication technologies. We then have your outputs, which are the most immediate set of accomplishments necessary, but not sufficient to produce the outcomes, which are your changes in behavior. Things like the households reached are included within the outputs. And then lastly, we have outcomes. These are, as I said, your changes in behavior. These are immediate, intermediate, observable, and measurable changes that can be attributed to extension and can result in ultimate impacts. Things like adoption, change in behavior, change in attitude and knowledge. There's one area we did not include and it would be interesting to discuss, and that is the ultimate impacts that's mentioned here. These are very difficult to measure and also difficult to attribute to extension programs. And Judy and David might discuss that further. We'll see. So what I have done here is to give you some background on the Extension Metrics Initiative and a quick overview of what we've done in terms of definitions and the start of the common framework, the outcome pillars, the target audience, and the domains. And with that, I'd like to turn it over to my colleague, Dr. David Spillman, to start to talk about the challenges of extension metrics. Thanks. All right. Thanks, Kristin. I hope everybody can still hear me. It's great to have such a large audience on AgriLinks with an interest in extension metrics. And it's very consistent, this large audience, with the evolution of thinking in many quarters on extension, in which we're moving from what's historically been a very strong focus on research metrics, that is the upstream source of science and technology for agricultural growth and transformation, to a new and very much complementary focus on the last mile and the downstream solutions for getting products and services to people, which includes information and extension recommendations. So, you know, quite naturally, we want to have indicators, benchmarks, and baselines to gauge progress on this front, on our sort of investments and our programs and our projects in extension. So let me offer a quick sort of reality check. There are some fundamental challenges in measuring extension. So let's start with, you know, what you might call sort of an epistemological debate. At a very basic level, it can be argued that extension cannot be isolated or identified, at least not in the way we define extension in our theory of change that Kristin presented in the earlier slides. I mean, let's face it. Do we really know what individuals employed by an agricultural service organization are doing? Are they providing farmers with advice? Or are they doing other things, monitoring crop production, distributing fertilizer and other inputs, collecting on overdue loans and so on? And even if extension can be isolated or identified, can it be quantified? Can quantitative measures adequately explain a complex system that is specific to farming systems, or agroecologies, society, culture, economy, and so on? And even if it can be quantified, are we sure we have a complete understanding of how extension works? Are we sure that extension leads to better farmers? Or do better farmers simply seek out extension services? All right. Let me make sure that everybody can still hear me. Yeah, I think I'm good. And then continuing, this sort of leads us to the broader debate of where indicators matter in our identified theory of change. Along with the impact pathway, we have to think carefully about what we're trying to measure. Are they proximate input indicators on sort of the level and reach of extension? Or are they more sort of, you know, distant outcome indicators, such as the causal relationship between extension and these productivity, income, or sustainability outcomes that we care about? We have to think carefully about the importance of attributing causality, which Kristin referred to earlier, or really understanding that relationship between extension on the one hand, and those outcomes of interest that we care about. And trying to demonstrate that they're more than simple correlations, and that we're accounting for confounding factors. In other words, you know, is there really a link between receiving extension services and, you know, improving your crop yields, or, you know, improving the sustainability of farming, or improving the welfare or income of a household or members of that household? It's a tough question. All right. But let's put those things aside for a moment and assume that we're comfortable with the idea, the very idea of measuring extension. So now we have to select, construct, and interpret some set of indicators. But there's no internationally accepted standard of what can be classified as, say, public spending on extension, or who's considered an extensionist or an extension agent, or how to classify capital equipment used in extension service provision. So thankfully, we have some precedent to build on here. An analogous set of questions and an analogous exercise began in the late 1980s in the measurement of agricultural research. IfPRE's agricultural science and technology indicators, for instance, collects, compiles, and disseminates internationally comparable data and information on investment in agricultural research. Its advantage, and what makes it distinct from the exercise we're talking about today on extension, is that the ASSEE metrics draw on comprehensive definitions of what constitutes research that were developed by the OECD and laid out in their Frascati manual. So maybe in the measurement of extension, we need to develop something similar. Maybe it's up to us to develop that manual or that guidance on how to measure extension and what constitutes extension. So a key principle of the ASSEE approach, or any approach really, is that we need to measure extension, or whatever it is we're measuring, at the point where the actual action takes place. It's the principle of subsidiarity. In ASSEE, they look at the Agricultural Research Center or Institute, or at the University Research Program or Lab. That same principle applied to extension, though, is a bit trickier. At what scale do extension metrics make analytical sense for data collection or for other purposes? Do we measure extension at sort of the central or federal level, or do we go hunting for data on extension at the state or provincial level, or at the county and district level, or even further down at the very local sort of village or community level? Do we measure by geography, agroecology, farming system, commodity, or value chain? Those are very different units of analysis. And do we focus on measuring public extension only, or do we try to get proprietary information from private firms on their customer support and advisory services? So, all of this suggests the need for data collection. And I would argue that if we want to track extension metrics over time and space, which is certainly the goal of this conversation, we need to collect new data, and definitely not repackage existing data. But collecting new data costs a lot of money. Thankfully, several new initiatives out there can help us, either by bringing useful data into our reach or by providing us with new data collection methods. For example, consider the World Bank's Living Standards Measurement Survey and its integrated surveys on agriculture, which provides cross-country comparability on questions such as whether a respondent has met with an extension officer in the last year or so. Or consider the Women's Empowerment Indicators under the Women's Empowerment in Agriculture Index that's been developed by colleagues of mine here in IFPRI and elsewhere. The WEA assembles novel data and analytics on how men and women live, work, and interact in the context of developing country agriculture. And a lot of these data points could be used to obtain a very valuable gendered perspective on extension, provision, and performance. So that leads us to what I think is really the essential question or the biggest challenge. Can extension metrics actually influence policy change? For example, by encouraging governments to invest more in extension or to undertake meaningful structural reforms in extension? For example, I think that the world has made tremendous progress in using evidence, data, evidence like we're talking about here, to advance policy change. But we all know that there are other factors like political imperatives that affect policy change much more than simply a set of good metrics. More importantly, even if we assume that our metrics have merit, we still need to ask if metrics are the right tool. I've heard a lot of very powerful people talk about using metrics to name and shame or rank and spank countries who don't invest enough in development priorities. But does that get us to the outcomes we really want? You know, extension systems are not a competitive sports league, like say the English Premier League, and the standings are there on the screen in front of you, or the National Football League here in the United States, where team rankings, points, and other statistics are the very essence of the game. A metric has to be actionable to be policy relevant. Otherwise, how does a policy maker do anything about a low score or a low rank? And a metric also has to be substantive so that policy makers cannot simply game the system by investing in one topic or solving one particular problem to somehow move themselves up the ranks. There's been a lot of critique of the World Bank's ease of doing business index or data collection and analysis projects along these lines. And it's something to think about very carefully. So having said all that, I think an attempt to measure extension is a tremendously good idea. And we're fortunate that the Gates Foundation, the Bill and Melinda Gates Foundation, along with several other key organizations have taken a stab at this challenge to guide their own investments and their own grant making. So what you have in front of you is a list of key indicators that the foundation is considering for their extension dashboard. They form what I would argue is a good starting point for any country or program considering an investment in developing local extension capacity. I'll walk through them very quickly for you and we can talk more about them later if you like. They are, for instance, the share of public budget spent on extension. And we would normalize that by dividing it by the total agricultural budget. So sort of a percentage-wise intensity measure. We could also normalize that on a per household basis. An interesting metric that they're proposing is financial incentives for extension agents, such as the ratio of an extension agent's daily wage to, let's say, a rural teacher's daily wage. Continuous improvement processes. So the proportion of extension personnel annually trained in specialized courses. persons. When I think about whether capacity awareness is required andään depensalels get done by however. There's a proportion ofilia intervention today who noted in related areas. Useful payment can be reached. So that's a strong amount of转ence guarantee to receivedscenes requirements. So while Yea it can restrictions. That's a fair number of fare. Everyone balances in a permanent way. Another observation doesn't have to select anyone from theirariatICO's tab best an example. They are currently related in a permanent link compared to revise potential unearthstone But also that<|bs|>ans have to огром�ges that people that can bring data to spend some greater use in a service environment Как providers are working on Apa-れる how to pass hard by 2030 personas to� días. Or service to female farmers, the share of females in smallholder households reporting that they received extension services. Or inclusivity, that is something like maybe an index of inclusivity of extension services relative to some defined disenfranchised or underserved population. So these are probably some of the metrics that we should be considering and I would argue they're a great starting point for this kind of initiative. On that note, let me just wind up my remarks simply by encouraging everyone to think about the feasibility, relevance, and influence of these kind of metrics in their own context, be it their own country context, the agroecologies that they're concerned about, the farming systems that they observe, the provinces or states they work in, or the value chains and commodities that they focus on. With that, let me hand it off to Judy Payne. Thank you very much. Thank you, David. I assume the handlers at AgriLinks will let me know if I'm not being heard well. Unlike Kristen and David, I do not have a research background and the academic discipline and clear experience that they have. Pardon? I came from the US private sector and then spent about a decade at USAID and have at least the strongest interest as Kristen and David and the others on the small task force we put together on figuring out better metrics for extension. I am especially interested in cost effectiveness of extension, given I've worked for government and, of course, are observed by government, and also the impact of extension on the poor, especially. I focus on digitally enabled extension. And digitally enabled extension providers and users often assume impact and cost effectiveness when that's not the case, or it certainly shouldn't be assumed. It may be other proven techniques are better. So, I think these metrics will help us get at that. I'm just going to pose a few questions and hope that they'll provoke thought from the audience and participation in additional questions from you. I wanted to point out that this is, we're presenting this as a point in time. It's definitely a work in progress. The informal task force of a handful of people is working towards the convening that Kristen mentioned that we hope to have in early 2019. We wanted to open up the discussion to more people to get feedback. We know the metrics we have and the work that we're doing is not as good as it can get, and we hope to get it much better before 2019. So please study these slides and give us feedback during the discussion, but also afterwards. You can contact any of us and also our colleagues at the Gates Foundation and the World Bank as well. So, I'll pose a couple of questions just to get the thinking going. David asked about whether this would influence decision making. And there is a concern that we try to set this up as some way for governments to compete, but I'd assert that if we can find some agreed upon metrics and even one country or two can stand up and say, I'm willing to be measured against that and show that they've made progress. I think that alone would be a great success. And then other countries might follow. Again, it's not like they're doing business indicators, but it still would be, I think, a point of pride for governments that are really struggling and working on improving their extension services. So, I think for decision policy making, it could have an effect. And we do know, and we want governments that are working on extension to participate in this convening to see whether they find these measures useful. Kristen also pointed out that we're looking at aspirational measures right now. Hold on just a minute. I want to just make sure everything's going okay. I will get out of full screen just to make sure. Okay. I think we're just fine. So, aspirational versus actually indicators that we can use now. David actually pointed out the many challenges to have metrics that we can collect for over time. All those things are certainly true. I'd say we still need to define things as aspirational and then see how close we can get with at least a few measures to start out. I'd be interested, if you think that we have forgotten any critical measures. Here, I'll go on to my next slide where I have additional questions. Have we gotten carried away? I think one danger is that we'll forget that most public extension services are directed to help farmers, but especially poor farmers. And do we have enough indicators to balance that interest, or will we be applauding extension services that go after the most able farmers and are not rewarded for doing the harder work sometimes of making sure the more remote farmers, the remote households can benefit from extension services. Before our convening, we want to make sure we've done homework by talking with others in a broader context. And maybe you have ideas of organizations you'd want to make sure we talk with, and it may be your organization. How well would this be accepted or be useful by agribusinesses, say, or private extension service providers? Are these measures irrelevant? Can additional ones be added? Is there metrics somehow to tackle how well the public extension service is leveraging private service providers? That's another really tough one. So, there's lots of questions. Again, this is a starting point, so we look forward to a rich discussion. I'm honored that I get to be the sort of provocateur on this. And I'm very pleased that we have people like Kristen and David with such experience to keep us disciplined as we go through this effort. So, I think I'll turn this over to Julie now, who can figure out what questions you all have. Julie Gale- Great. Thank you so much, Judy. And thanks also to your dog, Waldo, for his patience in waiting for you to present. We've had some fun side discussion about hearing him a little bit. But so, there are a lot of questions and comments coming in the chat box, which is wonderful. So, we'll go back and start with some of the questions that came in a bit earlier. I also wanted to reassure everyone that we will be sharing the chat box content with the presenters. So, any comments you type in that are answering some of the provocative questions that Judy has asked, your answers to those and your commentary will go to the presenters. And as Judy mentioned, there's also opportunity to think about these and provide commentary after this webinar. All right. So, looking back to some of the earlier questions that came in. Let's see. All right. Kristen or David, perhaps we can toss this one to Kristen to start. Viviana Palmieri asks, is there any reason why the system is limited to extension instead of considering the broader innovation systems? Or what other related systems are co-feasures? Thanks, Judy. Okay, go for it, David. I can take that one. Go ahead. Viviana, thank you very much for the question. Certainly, measuring attributes of the wider innovation system, which includes research and education, business and enterprise, and the general enabling environment, the role of cooperative and extension, among many other things, is important. Extension is just one element in a larger agricultural innovation system, and we acknowledge that. I think what we're trying to achieve here is simply putting some very small boundaries around what we can measure and hoping that contributes to broader measurement of the innovation system. For instance, in ag innovation systems, we do measure agricultural R&D through initiatives like ASTEE. We also look at measurements around educational achievement and performance systems and whatnot through RU Forum and others, and so on and so forth. The task of measuring every little aspect of an innovation system is very, very broad and very, very challenging. That's why in this particular exercise we're trying to parse it out to something that's directly relevant to sort of the investments and the choices and decisions that government and their development partners make to help them inform that process, that decision-making process. Thank you. Thank you. Thank you, David. Kristen, there were two questions that came in from Mahesh Shonder during your presentation, and so I thought I'd ask them both to you since they're both sort of short questions. One was, can we use the same metrics for different extension service providers? That very much depends on the goal or the outcome pillars that we're looking for. Some providers might be looking for public goods outcomes like food security and increasing incomes, and others might be looking for different goals and outcomes. It's going to really depend on your goal and your pillar, but we are trying to make a modular approach where you can sort of pick and choose what outcomes or indicators are going to work for you. I'm getting into Steve Franzel's question a little bit, but we'll address that later with regard to looking at the overall matrix that we've come up with. You also asked about productivity versus profitability, and we actually had that debate within the task force. We started off with productivity, and then we said, but that's not the ultimate goal. The ultimate goal is maybe to improve livelihoods or increase incomes or something like that. And so we do have an element of productivity. We might expand that. It's not just crop productivity. There can also be factor productivity issues as well, but we do include the element of profitability because that's a step beyond the productivity. We're going to be able to improve the growth of our growth and our growth and our growth and our growth and our growth and our growth and our growth and our growth and our growth and our growth and growth. Excellent. Thank you. All right. Let's jump up to – well, you mentioned that Steven had asked a question, so perhaps, Kristen, we can jump to his question. And Steve asked, how are the ten listed metrics linked to the overall objectives, goals, or desired impacts of extension? That would help us see gaps and overlap. So, I've probably thought that through, but a simple slide… Yeah. Thanks, Steve. And Judy and David, feel free to chime in after I've said my bit. We do have a rather complex-looking matrix that has your domains down the left side, and then the audience across the right, the pillars across the right. And then we've put in those initial Bill and Melinda Gates Foundation indicators, as well as some others that we've been looking at, exactly to do that, to see where are the gaps. And what we have seen is that there are a number of gaps in outcome pillars like sustainability and equity. So those are things that we're working on. It was really, I think, too tough to show to a webinar type of audience. But hopefully we're going to have something out of the task force in the coming months that we can share publicly, and you can see more clearly how it goes. This is Judy. I would echo what Kristen said. We were limited to what we could present, but the matrix that Kristen refers to is very useful for taking a look at what we're missing. And the question of equity is one where we need to think much further. I think once we work a little bit more, we'll get that matrix in some form, maybe multiple matrixes, out there for more review. Great. Thank you both. David, I'll ask a couple of questions that came in during your presentation. First up from Reginald Toussaint, based on your experience, what is the minimum timeframe to measure the impact of an extension system? All right. That's a tricky question. Obviously, if you're trying to measure, let's say, the impact of a large extension system reform process, right, changing salaries and incentives, you know, providing more or different infrastructure, creating, you know, new administrative routines and procedures, new leadership, things like that. You know, the timeframe may be anywhere from, what, two to five years, five to ten years. It's very hard to say, depending on what outcome indicators you care about. Things like profitability, productivity, incomes, and welfare obviously take some time to manifest. But in other instances, for instance, you can measure the impact of a very simple extension intervention in a single season. So I'll give you two examples that we've worked on under the Developing Local Extension Capacity Project funded by See the Future in USAID. In Ethiopia, working with Digital Green and the government of Ethiopia, we examined the impact of a video-enabled extension approach on farmers' adoption of new crop management practices for the main cereal crops. And we found that after one season, simply engaging farmers in sort of, you know, video screenings on new technologies and practices, that we saw increases in adoption levels by five to eight percentage points, which sort of translated into much larger adoption rates on the order of, you know, 15 to 20 percent against farmers. So we saw a lot of the use of the control, which is not a lot of the use of the control. So we saw a lot of the use of the control. In other words, we saw significant increases in adoption of new technologies after one season, simply by the video extension approach. In Uganda, we saw much of the same thing. And after one season, we were focusing on maize and the use of video-enabled or video-based extension approaches. And we actually saw increases not only in adoption, but also in yield, maize yields, based on what people learned in the videos about best management practices, recommended management practices. So if it's a simple, like, ICT-based intervention, you can measure a lot of impact in one season. If it's a structural reform process, well, that's a lot longer. Great, David. And allow me to throw one more out to you. You had discussed, you know, the difficulty of measuring ultimate impacts. I think Mahesh Chender added another kind of layer to that difficulty, which is that impact is an outcome of multiple factors. So how to isolate the impact due to extension, or, you know, should we even try? What do you think about that? Well, like in the examples I just gave from Ethiopia and Uganda, as well as work that other colleagues of mine have done in India and Peru and many other countries, I think with a well-designed evaluation strategy, you can definitely measure the impact of very specific extension interventions. To give you the example of what one of my colleagues did in Peru, he looked at, or they looked at, the impact of providing agronomic recommendations to children in high schools and trying to measure whether that affected what their parents did back on the farm. And, in fact, they found significant effects of the sort of intergenerational transfer of information. That's pretty exciting, right? You know, give extension messages in a school and, lo and behold, the parents actually adopt, you know, new practices on the farm. So you can certainly measure some of these things. The question is, you know, how, what are you trying to measure? How broad are you trying to measure? With good evaluation design, you can measure a lot of things. But, like I said earlier, if we're talking about systemic reforms, you probably need a lot of things. You probably need a lot more data to be able to, you know, control for or account for confounding influences, like changes in the political winds or changes in, you know, the weather over time, things like that, or changes in market forces and prices. As long as you can account for those kind of factors, there is possibility to suss out the impact of extension. But it can be challenging both in terms of data and sort of quality of inquiry. So, you know, your evaluation strategy really matters. But we do it all the time. We love to do it. And it's something that we love to explore with many of our partners. Great. Thank you, David. And thank you to all of our participants who are putting some really excellent questions and comments in the chat box. This has been an exciting discussion. And luckily, we still have a good amount of time to sort through these questions. All right. So there were a couple of questions that came in about private service providers. And so I'll ask them both, and we can perhaps answer them in combination. So Padma Singh asked about the presenter's thoughts on considering service providers and agrientrepreneurs as a target audience of agricultural extension. And then Catherine Killelew wanted to know about how does the private sector compare in terms of cost effectiveness of delivery and understanding those business cases. Let's see. And so perhaps I can throw that to Judy first. Okay. Well, I think I would distinguish between third-party service providers that are providing digitally enabled extension, ones that would be providing it for private agribusinesses as well as for public extension service providers. Say Digital Green does this. So they would be, I would assume several of these metrics would be relevant for them to be able to prove that their services are worth paying for by the public sector or an agribusiness. So that would be, I think, many of the metrics would apply directly. Another category of private sector folks at extension are those that are, say, sectoral associations for coffee or cocoa. So, these are very large plantation operators for pineapple or other large export crops. A very short list of the metrics might be relevant. If they get public funds, they would care about the ones related to equity. But I'd love to hear candidates who might be able to tell us whether these are relevant or not. You can just actually let us know in the chat window and we can later follow up. So, Kristen and David probably have some comments as well. All right. If Kristen or David would like to chime in on those, please feel free. Let's see. Otherwise, we'll move on to another question. Let's see. We've gotten so many good ones, so I'm just doing my best to sort through them all. Let's see. All right. For Kristen, Marisa Sturniste asked, are there targets or guidelines for any of these metrics? Once you get the data, how would you know if you're doing well? For example, is there a recommended area of public information? Thanks, Marisa. Very good question, and that's an important one as well. It does depend on the indicators. So, the FAO, for instance, has some recommendations of minimum budgets that should be spent on extension services or minimum number of extension agent to farmer ratio, things like that. But in general, I think a lot of the things, there is going to be no recommendation. Perhaps at national level, maybe the organization implementing it might have their own targets and so forth. Interestingly, I was on a webinar yesterday with people. The UNDP Green Commodities Program, and they are trying to set up a comparable sort of way to diagnose extension systems that would start with a baseline and give scores over the years. So, there are some related initiatives going on. But David or Judy, I'm not sure if you want to add anything to that. David or Judy, I can say, I guess, one thing. I think, you know, you can use metrics in so many ways. Cross-country comparability, for instance, gives you the, you know, a chance to see what those countries that you like to compare yourself to are doing and then think of that in an aspirational sense, saying, okay, China does this, we want to be like that, or Ethiopia does this, we want to be like that, for instance. But I think more importantly for any given country or program, these types of indicators are simply good to benchmark, you know, changes over time and look at, you know, what types of investments, what type of personnel, what type of resources are being channeled into extension, you know, over the years, and is it improving or is it not improving, and whether, you know, people perceive quality changes in the relevance and usefulness of extension. So, you know, you can use them in so many different ways. I guess, you know, like I was saying earlier in my presentation part, what you probably don't want to do is get into this, you know, sort of competitive, you know, race to the top, race to the bottom, because sometimes, you know, the context is so specific that, you know, one country is trying to get to where another country is, but the systems are really different or the challenges are really different, you know, does that serve anybody's purpose? Or if policymakers try to gain the system by throwing money at extension without thinking about, you know, quality or administration or incentives and things like that, does that really help things? So, there are, you know, using extension indicators in different ways is good, using them cautiously is even better. This is Judy. I have one related comment. Actually, it sort of veers us off the topic of goals, although I think that's a great question, and that will certainly depend on the comments that Chris and David made. I was thinking, I've read quite a bit about One Acre Fund lately, and it provides extension services, it provides financing, it provides inputs, it provides a package of things. It doesn't worry about distinguishing what its extension type services are doing versus its other services. It's focused primarily on scaling and outcome. So, it's sort of a counterpoint to the formidable effort we're talking about here, and in a way, it makes it easier for many organizations that might somewhat like that to look for results. So, maybe the third-party service providers could keep that in mind and give us comments on whether any of this is even relevant if you've got some focused goals of your own. Thank you, Judy. I'd like to ask perhaps to you, Judy, a couple of questions that are really related, I think, to what you were all just discussing about adapting the content of the framework. Niren Jaka Ramasindaratovo asked, do we want a measurement that is comparable globally, or something that is specific to the needs and context of each country? And Marissa Sturniste asked a related question, saying that these indicators are geared towards government or measuring at a higher administration level, can they be adapted to community-level interventions from NGOs, and how? Wow. Good questions. No simple answers. I'm sure Kristin and David could chime in as well. If we get good measures defined, they certainly can be used at a subnational level between communities, and with civil society organizations. They'll just have to pick and choose and figure out practical ways that they can use them. Clearly, they won't be able to do as rigorous of data collection as would be possible with an international organization like IFPRI. Coming from the private sector, I tend to have a more practical outlook on it. Some is better than nothing at all. And if we have metrics that we've together defined, then all the better. So try to use defined metrics and then figure out how well they'll work for you, for your organization, your community. Kristin and David, do you have more thoughtful comments? I guess just to say that international comparability has its pros and cons, and it can be useful, for for instance, for international development partners, multilateral and bilateral donor agencies, in making investment choices and decisions. That's why the Gates Foundation developed their dashboard, after all. That's why I'm sure Feed the Future, USAID, and many others care about these sort of international comparabilities that we're talking about. But, of course, at a government or country level and at an organizational level, they're also important. Some degree of standardization is helpful because, again, you can baseline and benchmark and compare, whether it's between organizations or states or countries or whatever you choose. And I think that's the key to indicators. Commonly accepted indicators make life, I think, a lot more useful or a lot easier than everybody choosing their own indicators. Thanks, David and Judy. David, let me throw another question out to you from Thomas Caffrey Oswald. How can the impact of extension services be effectively measured when one farmer may be receiving overlapping extension support, for example, from public extension service as well as from private sector, when coupled with investment in new technology or input? That's a great question. Again, it goes back to the response I gave to Mahesh earlier. It depends on your evaluation design and what you're trying to measure. So, you know, those are simply questions you can ask. We regularly ask them in farm household surveys where we ask people, farmers, where do they get information from about, you know, crop X or technology Y, and we allow for multiple responses. It might come from public extension or private extension sources or it might be some combination of both. And, you know, I've been in the field where a public extension agent is working with a corporate sales agent at the same time to promote a new cultivar, a new hybrid, a new, you know, a new machine or something like that. So, yeah, people work in tandem. People work in collaborative ways. I think that's perfectly fine. And, you know, as long as you're able to account for that and have that information, then, you know, you can parse out the effects. I mean, you know, sometimes there's an art to this. Sometimes there's a science to it. It really depends on what the intention of your evaluation is. If you're trying to say, okay, you know, my NGO did this and the government didn't, then, you know, that's a fairly, I think, narrow assessment approach or evaluation approach. If you're trying to say, well, you know, information from, you know, these types of sources led to the outcomes we care about, then that might be, I think, a more realistic way of approaching the problem or the question. It really ultimately depends on what your learning objectives and what your evaluation objectives are in this case. Great. Thank you, David. All right. Let's see. Kristen, I will throw a question to you from Vicki Sigman. Is the expectation that public sector extension will support, i.e., pay for, data collection? Or otherwise, what role will they play? If the public sector is to support this, then are there clear indications that the governments will... Thanks. Hi, Vicki. Thanks for your excellent question. There is some expectation that there will be interest on the side of governments. And actually, this is part of the role of the task force now in the next few months, is to go and to start to talk to potential governments that we think would be interested, and to see, are they interested in collecting extension metrics, and then invite them to the convening in Uganda in February, and sit down and hash through it a little bit more. So how it's going to be done is yet to be seen. It might be different in every country, but there is the expectation that there's going to be funding, whether it's coming from a sort of an outside donor or governments, in terms of using these data to inform and advocate for their policies for extension. That remains to be seen. Thank you, Kristen. And we still have some good time for questions, but I just wanted to flag a few upcoming events and activities on AgriLynx. First, the Feed the Future Learning Agenda, the draft agenda for Phase 2 of Feed the Future, is currently open for public comment. And you can see the draft learning agenda and a survey link for commenting there next to number one. Number two, if you are a student or you know one who is working in the food security and agriculture space, AgriLynx is currently having a Young Scholars blog contest by which students can submit their blog posts about their work, or their insights on global food security. And we're going to pick, with a panel of USAID and AgriLynx individuals, we're going to pick the top blog posts to publish and feature on AgriLynx. So do encourage the students in your life to apply. And lastly, we wanted to announce the October theme month for AgriLynx. Right now we're in Extension month, clearly. But next month is going to be Value Added Food Month, which I'm really excited to talk about. We'll probably be having a webinar on orange fleshed soup potato and been talking about all of the entrepreneurial ways that farmers, processors, other actors can add value to food for better incomes and better nutrition. So keep all of those in mind. Oh, and I also wanted to point out, in the links box to your left, you'll see a link for the DELEC community of practice. We definitely encourage everyone on this webinar to join that community of practice. There will be a lot of additional ways to discuss these topics through that website and through some webinar and other discussion opportunities that DELEC presents. So don't hesitate to join that COP. All right. So back to...oh, we've got a bit of an enlargement of that links box, but we'll go ahead and bring that back down. So that was just really telling you all to click on those links. Excellent. Okay. So back to the questions that have come in. Okay. I will go to a question that came in from Kathy Peary. In the 10 common metrics, the quality of public extension is a metric, but the same approach of determining quality is not applied to the private sector. Is it implicitly implied that private sector extension does not need to be assessed for quality of extension? And Judy, was that one that you could address? Sure. I'll start. Having come from the private sector, I mean, the private sector cares a lot about success, and it defines what its success means. If it's getting donor money, of course, it cares a lot what donors care about. But say a private company that owns a pineapple plantation cares a lot about productivity. It cares a lot about making sure its workers stick to them and we hope are treated well. We can't...these metrics will be decided by...or not by the private sector. But maybe some of the others could chime in. But certainly any service provider cares a lot about showing how effective their services are. So those metrics will be truly relevant. Yeah. I can quickly add to that. I'd say that we have some experience on the measurement of agricultural research indicators to say what's possible and what's not possible. Measuring both the levels and the type of private investment in agricultural research, for instance, has proven to be very difficult, especially for initiatives like ASTI, which I mentioned earlier. And that's largely because ag research indicators, that is, you know, investment, spending, things like that, personnel, and so on, are proprietary information. They form...for many companies, they form the basis of their competitive advantage in the market...you know, in very competitive marketplaces. So think along the same lines for extension. If you're an agri-service provider of some sort, you're private, you're profit-making, you don't necessarily, you know, want to give out information on, hey, how many people do we have on the ground providing after-sales support or providing, you know, recommendations to farmers and advice on an ad hoc basis or, you know, through our call center or whatever it is. That might be proprietary information that, you know, that the company wants to protect. So that becomes very difficult to get. So, you know, but that doesn't imply that it's not...that the quality of private extension is not an important measure. As Judy said, you know, people care about the quality of their products in the private sector as much, if not more, than they do in the public sector. So somebody's measuring it, it's just a question of whether it's going to be shared in the public domain or not. Thank you. Great. Thank you so much. I'd like to toss it back to you, David, for a really interesting question that came in from Sevak Amalyan. Looking at the Gates metrics, what if we were to reach 100% of households covered by extension, have a very generous public budget, service to females, et cetera, but no essential increase in yield for hectare, no increase in production and trade? Are those the most important and probably the only metrics that matter? That's a great question, Sevak. I saw it earlier and I had to laugh. It's...yes, it's precisely what one wants to be asking. The proof is in the pudding, as they say. If you measure something but you can't attribute that measurement to some outcome of interest, then maybe...the problem isn't your measurement so much as it is your theory of change. So what you're basically describing here is a situation in which your theory of change doesn't stand up to, you know, empirical testing. And that extension has no effect on these outcomes of interest. In which case, you probably have to go back to the drawing board and say, well, extension really has nothing to do with, you know, productivity, profitability, incomes, welfare, environmental sustainability, and so on and so forth. Now, of course, whether, you know, whether that's really the case is a bigger question. And I think that's, again, where we go back to good evaluation design and saying, okay, you know, we've got some measurements on extension, and now we want to go back and make sure that we're able to say that, you know, these measurements are somehow correlated and potentially infer causality about their, you know, their influence on outcomes. So, yeah, there's a lot of sort of, you know, hypothesis testing in all of this, not just measurement. And that's something we have to be very, very, I think, serious about in our work. Thank you, David. And I would like to throw out another question that came in from Amadou Issaka. Can we use the same approach to measure quality outcomes, like, for instance, the functionality of innovations platform, farmers' capacity to mobilize funds from institutions, et cetera? And that was for David or Kristen. Yeah, I'll start and you can fill in the gaps. Yeah, thanks for your question. I mean, I think this is an approach that can be applied in other similar institutions. I mean, extension is quite a complex institution. And then when you're getting into innovation platforms and things like that, it includes even more variables and actors and so forth. But I think the general setup of how we're looking at this and applying things based on those different domains as well as the different outcome pillars, I think we could try to apply it to similar activities like innovation platforms and so forth. David? David? David? David? David? David? David? So there's been some interesting work on the measurement of the functionality of innovation platforms, for instance, by Pamuk at at least Bacheningen University in the Netherlands, as well as his colleagues. So, yes, I mean, you can certainly measure those types of outcomes. You can measure things like farmers' capacity to mobilize funds from financial institutions and so on. Those are all indicators that you can look at. And whether they're somehow linked to extension, you know, depends on how you structure your thinking, your theory of change, and how you measure it. I would suggest that if you're really interested in these topics and poking around in the data, take a look at the LSMS integrated surveys on agriculture from the World Bank that I mentioned earlier. I mean, there's an incredible amount of information there that people are really digging through intensively to learn more about exactly the kind of questions you're asking. You know, and the right kind of data analysis and approaches are key to answering the questions you're asking, but they're good ones to explore. All right. Let's see. Okay. So, interesting comments came in from Gary Alex that I thought that Kristen could address. So, Gary said, for an understanding of extension systems, it is probably important to start from the farmer level to understand the needs, objectives, preferences, and potential actors. Too often we have gaps in the understanding and perspective and treat the farmer as a blank slate to be worked on. It is hard to think of how this might be reflected in an indicator, but it is important to develop the effective... Yes. Hi, Gary. My first comment is that we're going to try to rope you into this task force. I don't know if John got in touch with you yet, but we'd love your inputs on it. Certainly, for an extension program to be relevant, and as you say, effective, and all of these things, I mean, it's got to be relevant and useful to the clientele, and the extension services need to have that client-oriented approach. So, we do need to have their opinions. It would be interesting to look for some indicators to reflect that, and it's, of course, again, going to depend on our ultimate program goals and program objectives. So, if we're trying to empower farmers and have a demand-driven program, that's certainly one that we would want to encourage. Great. And I think, David, you said you had some additional comments. Sure. So, let me see if I can tackle two comments. One is related to what Gary Alex said, and another one from Andrea Bon on the importance of using data collected from farmers to provide feedback to farmers. So, both of these comments have a similar thread or a similar vein, which is that, you know, often when we think about metrics and indicators, we're really top-down in how we think about things, right? We're thinking at this big system level, and we want to measure things so we have international comparability and we can, you know, steer our investments in the right way. Well, that's all good and fine, but if we don't really understand sort of what's going on at the grassroots level, and if we're not really using the type of information to inform people at the grassroots level, then we're probably falling short of our objectives. I mean, you know, I couldn't agree more. I mean, I think that's exactly the way we should be thinking about development processes. Development processes, economic and social development, do not occur on the basis of what we think about in Washington, D.C., or Seattle, or London, or Paris, or wherever. They happen at the grassroots where people exist. And the more we think about farmers as a diverse set of people that are more than just farmers, the better we are at understanding how to tailor Extension services to fit their needs. One of the things we care about in particular when we're looking at indicators of, you know, how well is Extension achieving the outcomes that we're focused on is to think not at the average effect size or the magnitude of the average effect, but also to parse it out and think a little bit about how certain subgroups are affected. So, for instance, thinking about, you know, the work in Uganda. Uganda has an inordinately large number of women-headed households because of demographic pressures associated not just with urbanization, but also the HIV-AIDS pandemic that the country has suffered through for decades. So, focusing on that particular subpopulation is really important. Women-headed households or children and youth-headed households in Uganda are a significant part of the population that we don't think about much. So, focusing on them, getting, you know, getting a better understanding of what Extension does and doesn't do for them is a great way to address these issues. So, yes, I think starting from the bottom up and worrying less about, not worrying less, but, you know, maintaining a balance between what we think of at the grassroots and what we think of at this much higher systems level is necessary. Balance is everything. Thank you. Great. Very interesting answer. Thank you to both of you. Let's see. We do have about up to ten more minutes for questions, but in the meantime we wanted to throw up a few poll questions for all of you to help us better understand your experience on the webinar. So, we'd love to know how likely it is that you would recommend this webinar to a friend or colleague. Did anything surprise you from the content of this webinar? Are you walking away with any new insights? What was not addressed that we could potentially address in the future? Asking about if you'd like to stay involved in the Common Metrics Initiative so that we can continue to reach out to you? And what was most useful to your work? So, please do let us know your answers to these questions. They'll help us better shape future webinars and events. All right. Let's see. We've got just a few more questions that I think we can answer. And a question slash comment came in from Suzanne Pullins that I will toss out. Suzanne said, farming is a business. How do business advisory services measure impact? What metrics do these business advisory services use? And could these be relevant to farming businesses and other agribusinesses? And, Judy, we thought perhaps you could start on that question. Actually, I would ask Suzanne to answer that question. She's an expert on all of this. So, and I've learned a lot from her and hope to continue. So, I don't have any answer that Suzanne probably wouldn't have herself. Clearly, farming is a business. It's more than a business. It's a household livelihood. So, measuring business services as part of it, as part of extension is a big challenge. Both Kristen and David are better students of the definition of extension and where business advisory services fit in. So, maybe they can comment on where, what metric would tackle that. Great. Thanks. And, Suzanne, if you're still online, we'd love to know your further commentary on your own question. All right. And, Judy, let me toss another one out to you from Padma Singh. How do we ensure that producers are getting fair share in benefit in private sector extension? Does the governor or does the government have a role here? I say follow the money. If the government has money in those services being provided or a donor does, then, yes, the government is. has a role in measuring that. And, of course, in some countries there are rules about how farmers or those getting services should be served or treated. Clearly, if a private company is providing these services on its own for its own gains and that of its owners, then the government has far less of a role. And given I came from the private sector, I certainly honor that. Private businesses have strong reasons to measure their own success. Private businesses have strong reasons to measure their own success. They surely have to protect those that they serve through various other laws. But applying these metrics by the government on totally private service providers, I don't think, we'd have to do that with great caution. And maybe do it voluntarily so that the private service providers can have an incentive to do it to show how well they serve their audience. Thank you, Judy. Cristen, a question just came in from Ed Connerly. Are there trade-offs between aspirations and the likelihood of aspirations? Yeah, to that question, I think there's a number of people on the webinar, Gary and Andrea, David and myself, who have been trying to measure extension and struggling with indicators and data and so forth. So it is a trade-off. I mean, there's the data we ideally would like to have and we're starting from there and we're going to try to get it and see how it works. In the end, it might be necessary to come down to what's going to be more feasible and more easy to collect. So we're going to see about piloting this in one or more countries and take it from there and see what works. Great. Thank you, Kristin. And David, let me look way back to your presentation for a question that came in fairly early on from Hamadur Rahman, who said, it is difficult to measure outcomes in terms of monetary value. Is there any good indicator available for the researchers or just a little bit more perspective on measuring monetary value? It depends on which outcomes you are interested in. Monetary value can certainly be measured to give you a sense. We've been talking a lot about profitability of farming or on-farm activities. So if we want to put a monetary value on that, you know, we look at the cost and returns to cultivation of a particular crop or commodity or to the whole farm's overall profitability. You know, when you think about simply yield gains, right, you can translate that into monetary value by multiplying the quantity of production increased multiplied by the price of the crop involved. So that gives it a monetary value. Income, of course, is a monetary phenomenon. Welfare can be measured in other ways apart from income in both monetary and non-monetary ways. There are lots of different ways to measure these things, and they can, you know, be boiled down to monetary measures or non-monetary as well. What's important, I think, is, you know, to get a sense of sort of the, you know, the rate of – the differences in the rate of change, you know, that are attributable to extension. And those levels and trends are what give us a sense of performance and impact. Thank you. Thank you so much, David. All right. So we've had a lot of questions come in, some really great discussion. We really, really appreciate all of you who have joined us as attendees, liberally sharing your questions and comments. They're very helpful to the DLAC team who are helping to create these metrics. And, of course, joining the DLAC community of practice is one of the best ways to continue to stay informed on this topic. In addition, we'll be sending out an email with the recording of this webinar, the PowerPoint, a few additional resources, the chat box transcript, et cetera. And in that email, we'll be sure to communicate any essential follow-up actions from this webinar. So I'd like to go ahead and wrap up the webinar and say a sincere thank you to Judy, David, and Kristen for your excellent presentations. Thank you to the AgriLynx team who is always wonderful in supporting and putting on these webinars. And most importantly, thank you to you, the attendees, for continuing to come to AgriLynx webinars. Thank you, Ellen Eلكmy. I'll be right back in the dark� for a couple of things. When we've talked about how many new-carri perlu